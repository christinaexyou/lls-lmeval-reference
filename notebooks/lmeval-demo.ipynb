{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Building Custom Distribution of LLamaStack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import logging\n",
    "import requests\n",
    "\n",
    "import pprint\n",
    "\n",
    "from llama_stack.distribution.library_client import LlamaStackAsLibraryClient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: `bwrap` is not available. Code interpreter tool will not work correctly.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Using config <span style=\"color: #000080; text-decoration-color: #000080\">.stack-run.yaml</span>:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Using config \u001b[34m.stack-run.yaml\u001b[0m:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">apis:\n",
       "- inference\n",
       "- agents\n",
       "- vector_io\n",
       "- safety\n",
       "- eval\n",
       "- datasetio\n",
       "- scoring\n",
       "- telemetry\n",
       "- tool_runtime\n",
       "benchmarks: <span style=\"font-weight: bold\">[]</span>\n",
       "container_image: null\n",
       "datasets: <span style=\"font-weight: bold\">[]</span>\n",
       "image_name: <span style=\"color: #800080; text-decoration-color: #800080\">/Users/chrxu/Documents/llama-stack/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">.stack</span>\n",
       "logging: null\n",
       "metadata_store: null\n",
       "models: <span style=\"font-weight: bold\">[]</span>\n",
       "providers:\n",
       "  agents:\n",
       "  - config:\n",
       "      persistence_store:\n",
       "        db_path: <span style=\"color: #800080; text-decoration-color: #800080\">/Users/chrxu/.llama/distributions//Users/chrxu/Documents/llama-stack/.stack/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">agents_store.db</span>\n",
       "        namespace: null\n",
       "        type: sqlite\n",
       "    provider_id: meta-reference\n",
       "    provider_type: inline::meta-reference\n",
       "  datasetio:\n",
       "  - config:\n",
       "      kvstore:\n",
       "        db_path: \n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">/Users/chrxu/.llama/distributions//Users/chrxu/Documents/llama-stack/.stack/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">huggingface_datasetio.db</span>\n",
       "        namespace: null\n",
       "        type: sqlite\n",
       "    provider_id: huggingface-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "    provider_type: remote::huggingface\n",
       "  - config:\n",
       "      kvstore:\n",
       "        db_path: <span style=\"color: #800080; text-decoration-color: #800080\">/Users/chrxu/.llama/distributions//Users/chrxu/Documents/llama-stack/.stack/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">localfs_datasetio.db</span>\n",
       "        namespace: null\n",
       "        type: sqlite\n",
       "    provider_id: localfs-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "    provider_type: inline::localfs\n",
       "  eval:\n",
       "  - config:\n",
       "      kvstore:\n",
       "        db_path: <span style=\"color: #800080; text-decoration-color: #800080\">/Users/chrxu/.llama/distributions//Users/chrxu/Documents/llama-stack/.stack/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">meta_reference_eval.db</span>\n",
       "        namespace: null\n",
       "        type: sqlite\n",
       "    provider_id: meta-reference-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "    provider_type: inline::meta-reference\n",
       "  - config:\n",
       "      base_url: <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://vllm-test.apps.rosa.p2i7w2k6p6w7t7e.3emk.p3.openshiftapps.com/v1/completions</span>\n",
       "      namespace: test\n",
       "      use_k8s: true\n",
       "    provider_id: lmeval-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "    provider_type: remote::lmeval\n",
       "  inference:\n",
       "  - config:\n",
       "      api_token: <span style=\"color: #008000; text-decoration-color: #008000\">'********'</span>\n",
       "      max_tokens: <span style=\"color: #008000; text-decoration-color: #008000\">'4096'</span>\n",
       "      tls_verify: <span style=\"color: #008000; text-decoration-color: #008000\">'true'</span>\n",
       "      url: <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://vllm-test.apps.rosa.p2i7w2k6p6w7t7e.3emk.p3.openshiftapps.com/v1/completions</span>\n",
       "    provider_id: vllm-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "    provider_type: remote::vllm\n",
       "  - config: <span style=\"font-weight: bold\">{}</span>\n",
       "    provider_id: sentence-transformers-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "    provider_type: inline::sentence-transformers\n",
       "  safety:\n",
       "  - config:\n",
       "      excluded_categories: <span style=\"font-weight: bold\">[]</span>\n",
       "    provider_id: llama-guard\n",
       "    provider_type: inline::llama-guard\n",
       "  scoring:\n",
       "  - config: <span style=\"font-weight: bold\">{}</span>\n",
       "    provider_id: basic-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "    provider_type: inlin<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e::ba</span>sic\n",
       "  - config: <span style=\"font-weight: bold\">{}</span>\n",
       "    provider_id: llm-as-judge-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "    provider_type: inline::llm-as-judge\n",
       "  - config:\n",
       "      openai_api_key: <span style=\"color: #008000; text-decoration-color: #008000\">'********'</span>\n",
       "    provider_id: braintrust-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>\n",
       "    provider_type: inlin<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e::b</span>raintrust\n",
       "  telemetry:\n",
       "  - config:\n",
       "      sinks: sqlite\n",
       "      sqlite_db_path: <span style=\"color: #800080; text-decoration-color: #800080\">/Users/chrxu/.llama/distributions//Users/chrxu/Documents/llama-stack/.stack/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">trace_store.db</span>\n",
       "    provider_id: meta-reference\n",
       "    provider_type: inline::meta-reference\n",
       "  tool_runtime:\n",
       "  - config:\n",
       "      api_key: <span style=\"color: #008000; text-decoration-color: #008000\">'********'</span>\n",
       "      max_results: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>\n",
       "    provider_id: brave-search-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "    provider_type: remot<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e::b</span>rave-search\n",
       "  - config:\n",
       "      api_key: <span style=\"color: #008000; text-decoration-color: #008000\">'********'</span>\n",
       "      max_results: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>\n",
       "    provider_id: tavily-search-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "    provider_type: remote::tavily-search\n",
       "  - config: <span style=\"font-weight: bold\">{}</span>\n",
       "    provider_id: code-interpreter-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>\n",
       "    provider_type: inlin<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e::c</span>ode-interpreter\n",
       "  - config: <span style=\"font-weight: bold\">{}</span>\n",
       "    provider_id: rag-runtime-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>\n",
       "    provider_type: inline::rag-runtime\n",
       "  - config: <span style=\"font-weight: bold\">{}</span>\n",
       "    provider_id: model-context-protocol-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>\n",
       "    provider_type: remote::model-context-protocol\n",
       "  - config:\n",
       "      api_key: <span style=\"color: #008000; text-decoration-color: #008000\">'********'</span>\n",
       "    provider_id: wolfram-alpha-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>\n",
       "    provider_type: remote::wolfram-alpha\n",
       "  vector_io:\n",
       "  - config:\n",
       "      kvstore:\n",
       "        db_path: <span style=\"color: #800080; text-decoration-color: #800080\">/Users/chrxu/.llama/distributions//Users/chrxu/Documents/llama-stack/.stack/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">faiss_store.db</span>\n",
       "        namespace: null\n",
       "        type: sqlite\n",
       "    provider_id: faiss\n",
       "    provider_type: inlin<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e::fa</span>iss\n",
       "scoring_fns: <span style=\"font-weight: bold\">[]</span>\n",
       "server:\n",
       "  auth: null\n",
       "  port: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8321</span>\n",
       "  tls_certfile: null\n",
       "  tls_keyfile: null\n",
       "shields: <span style=\"font-weight: bold\">[]</span>\n",
       "tool_groups: <span style=\"font-weight: bold\">[]</span>\n",
       "vector_dbs: <span style=\"font-weight: bold\">[]</span>\n",
       "version: <span style=\"color: #008000; text-decoration-color: #008000\">'2'</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "apis:\n",
       "- inference\n",
       "- agents\n",
       "- vector_io\n",
       "- safety\n",
       "- eval\n",
       "- datasetio\n",
       "- scoring\n",
       "- telemetry\n",
       "- tool_runtime\n",
       "benchmarks: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "container_image: null\n",
       "datasets: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "image_name: \u001b[35m/Users/chrxu/Documents/llama-stack/\u001b[0m\u001b[95m.stack\u001b[0m\n",
       "logging: null\n",
       "metadata_store: null\n",
       "models: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "providers:\n",
       "  agents:\n",
       "  - config:\n",
       "      persistence_store:\n",
       "        db_path: \u001b[35m/Users/chrxu/.llama/distributions/\u001b[0m\u001b[35m/Users/chrxu/Documents/llama-stack/.stack/\u001b[0m\u001b[95magents_store.db\u001b[0m\n",
       "        namespace: null\n",
       "        type: sqlite\n",
       "    provider_id: meta-reference\n",
       "    provider_type: inline::meta-reference\n",
       "  datasetio:\n",
       "  - config:\n",
       "      kvstore:\n",
       "        db_path: \n",
       "\u001b[35m/Users/chrxu/.llama/distributions/\u001b[0m\u001b[35m/Users/chrxu/Documents/llama-stack/.stack/\u001b[0m\u001b[95mhuggingface_datasetio.db\u001b[0m\n",
       "        namespace: null\n",
       "        type: sqlite\n",
       "    provider_id: huggingface-\u001b[1;36m0\u001b[0m\n",
       "    provider_type: remote::huggingface\n",
       "  - config:\n",
       "      kvstore:\n",
       "        db_path: \u001b[35m/Users/chrxu/.llama/distributions/\u001b[0m\u001b[35m/Users/chrxu/Documents/llama-stack/.stack/\u001b[0m\u001b[95mlocalfs_datasetio.db\u001b[0m\n",
       "        namespace: null\n",
       "        type: sqlite\n",
       "    provider_id: localfs-\u001b[1;36m1\u001b[0m\n",
       "    provider_type: inline::localfs\n",
       "  eval:\n",
       "  - config:\n",
       "      kvstore:\n",
       "        db_path: \u001b[35m/Users/chrxu/.llama/distributions/\u001b[0m\u001b[35m/Users/chrxu/Documents/llama-stack/.stack/\u001b[0m\u001b[95mmeta_reference_eval.db\u001b[0m\n",
       "        namespace: null\n",
       "        type: sqlite\n",
       "    provider_id: meta-reference-\u001b[1;36m0\u001b[0m\n",
       "    provider_type: inline::meta-reference\n",
       "  - config:\n",
       "      base_url: \u001b[4;94mhttps://vllm-test.apps.rosa.p2i7w2k6p6w7t7e.3emk.p3.openshiftapps.com/v1/completions\u001b[0m\n",
       "      namespace: test\n",
       "      use_k8s: true\n",
       "    provider_id: lmeval-\u001b[1;36m1\u001b[0m\n",
       "    provider_type: remote::lmeval\n",
       "  inference:\n",
       "  - config:\n",
       "      api_token: \u001b[32m'********'\u001b[0m\n",
       "      max_tokens: \u001b[32m'4096'\u001b[0m\n",
       "      tls_verify: \u001b[32m'true'\u001b[0m\n",
       "      url: \u001b[4;94mhttps://vllm-test.apps.rosa.p2i7w2k6p6w7t7e.3emk.p3.openshiftapps.com/v1/completions\u001b[0m\n",
       "    provider_id: vllm-\u001b[1;36m0\u001b[0m\n",
       "    provider_type: remote::vllm\n",
       "  - config: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
       "    provider_id: sentence-transformers-\u001b[1;36m1\u001b[0m\n",
       "    provider_type: inline::sentence-transformers\n",
       "  safety:\n",
       "  - config:\n",
       "      excluded_categories: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "    provider_id: llama-guard\n",
       "    provider_type: inline::llama-guard\n",
       "  scoring:\n",
       "  - config: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
       "    provider_id: basic-\u001b[1;36m0\u001b[0m\n",
       "    provider_type: inlin\u001b[1;92me::ba\u001b[0msic\n",
       "  - config: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
       "    provider_id: llm-as-judge-\u001b[1;36m1\u001b[0m\n",
       "    provider_type: inline::llm-as-judge\n",
       "  - config:\n",
       "      openai_api_key: \u001b[32m'********'\u001b[0m\n",
       "    provider_id: braintrust-\u001b[1;36m2\u001b[0m\n",
       "    provider_type: inlin\u001b[1;92me::b\u001b[0mraintrust\n",
       "  telemetry:\n",
       "  - config:\n",
       "      sinks: sqlite\n",
       "      sqlite_db_path: \u001b[35m/Users/chrxu/.llama/distributions/\u001b[0m\u001b[35m/Users/chrxu/Documents/llama-stack/.stack/\u001b[0m\u001b[95mtrace_store.db\u001b[0m\n",
       "    provider_id: meta-reference\n",
       "    provider_type: inline::meta-reference\n",
       "  tool_runtime:\n",
       "  - config:\n",
       "      api_key: \u001b[32m'********'\u001b[0m\n",
       "      max_results: \u001b[1;36m3\u001b[0m\n",
       "    provider_id: brave-search-\u001b[1;36m0\u001b[0m\n",
       "    provider_type: remot\u001b[1;92me::b\u001b[0mrave-search\n",
       "  - config:\n",
       "      api_key: \u001b[32m'********'\u001b[0m\n",
       "      max_results: \u001b[1;36m3\u001b[0m\n",
       "    provider_id: tavily-search-\u001b[1;36m1\u001b[0m\n",
       "    provider_type: remote::tavily-search\n",
       "  - config: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
       "    provider_id: code-interpreter-\u001b[1;36m2\u001b[0m\n",
       "    provider_type: inlin\u001b[1;92me::c\u001b[0mode-interpreter\n",
       "  - config: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
       "    provider_id: rag-runtime-\u001b[1;36m3\u001b[0m\n",
       "    provider_type: inline::rag-runtime\n",
       "  - config: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
       "    provider_id: model-context-protocol-\u001b[1;36m4\u001b[0m\n",
       "    provider_type: remote::model-context-protocol\n",
       "  - config:\n",
       "      api_key: \u001b[32m'********'\u001b[0m\n",
       "    provider_id: wolfram-alpha-\u001b[1;36m5\u001b[0m\n",
       "    provider_type: remote::wolfram-alpha\n",
       "  vector_io:\n",
       "  - config:\n",
       "      kvstore:\n",
       "        db_path: \u001b[35m/Users/chrxu/.llama/distributions/\u001b[0m\u001b[35m/Users/chrxu/Documents/llama-stack/.stack/\u001b[0m\u001b[95mfaiss_store.db\u001b[0m\n",
       "        namespace: null\n",
       "        type: sqlite\n",
       "    provider_id: faiss\n",
       "    provider_type: inlin\u001b[1;92me::fa\u001b[0miss\n",
       "scoring_fns: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "server:\n",
       "  auth: null\n",
       "  port: \u001b[1;36m8321\u001b[0m\n",
       "  tls_certfile: null\n",
       "  tls_keyfile: null\n",
       "shields: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "tool_groups: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "vector_dbs: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "version: \u001b[32m'2'\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# llama stack build --image-type venv --config llama_stack/templates/lm-eval/lm-eval-build.yaml\n",
    "client = LlamaStackAsLibraryClient(\".stack-run.yaml\")\n",
    "_ = client.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_http_client():\n",
    "    from llama_stack_client import LlamaStackClient\n",
    "    return LlamaStackClient(base_url=\"http://localhost:8321\")\n",
    "\n",
    "client = create_http_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Provider: meta-reference-0\n",
      "\n",
      "Provider: lmeval-1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sanity check for lmeval as a registered provider\n",
    "providers = client.providers.list()\n",
    "for provider in providers:\n",
    "    if provider.api == \"eval\":\n",
    "        print(f\"Provider: {provider.provider_id}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Run LM-Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': [{'dataset_id': 'lmeval::mmlu',\n",
      "           'identifier': 'lmeval::mmlu',\n",
      "           'metadata': {},\n",
      "           'provider_id': 'lmeval-1',\n",
      "           'provider_resource_id': 'string',\n",
      "           'scoring_functions': ['string'],\n",
      "           'type': 'benchmark'},\n",
      "          {'dataset_id': 'lmeval:mmlu',\n",
      "           'identifier': 'lmeval:mmlu',\n",
      "           'metadata': {},\n",
      "           'provider_id': 'lmeval-1',\n",
      "           'provider_resource_id': 'string',\n",
      "           'scoring_functions': ['string'],\n",
      "           'type': 'benchmark'}]}\n"
     ]
    }
   ],
   "source": [
    "url = \"http://0.0.0.0:8321/v1/eval\"\n",
    "\n",
    "response = requests.get(f\"{url}/benchmarks\")\n",
    "\n",
    "if response.status_code == 200:\n",
    "   pprint.pprint(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"benchmark_id\": \"lmeval::mmlu\",\n",
    "    \"dataset_id\": \"lmeval::mmlu\",\n",
    "    \"scoring_functions\": [\"string\"],\n",
    "    \"provider_benchmark_id\": \"string\",\n",
    "    \"provider_id\": \"lmeval-1\"\n",
    "}\n",
    "response = requests.post(f\"{url}/benchmarks\", json=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': [{'dataset_id': 'lmeval::mmlu',\n",
      "           'identifier': 'lmeval::mmlu',\n",
      "           'metadata': {},\n",
      "           'provider_id': 'lmeval-1',\n",
      "           'provider_resource_id': 'string',\n",
      "           'scoring_functions': ['string'],\n",
      "           'type': 'benchmark'},\n",
      "          {'dataset_id': 'lmeval:mmlu',\n",
      "           'identifier': 'lmeval:mmlu',\n",
      "           'metadata': {},\n",
      "           'provider_id': 'lmeval-1',\n",
      "           'provider_resource_id': 'string',\n",
      "           'scoring_functions': ['string'],\n",
      "           'type': 'benchmark'}]}\n"
     ]
    }
   ],
   "source": [
    "# Make the GET request\n",
    "response = requests.get(f\"{url}/benchmarks\")\n",
    "pprint.pprint(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "serviceaccount/lmeval-sa unchanged\n",
      "clusterrole.rbac.authorization.k8s.io/lmeval-role unchanged\n",
      "clusterrolebinding.rbac.authorization.k8s.io/lmeval-rolebinding unchanged\n",
      "role.rbac.authorization.k8s.io/lmeval-role unchanged\n",
      "rolebinding.rbac.authorization.k8s.io/lmeval-rolebinding unchanged\n",
      "role.rbac.authorization.k8s.io/lmeval-role unchanged\n",
      "rolebinding.rbac.authorization.k8s.io/lmeval-rolebinding unchanged\n"
     ]
    }
   ],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def setup_cluster():\n",
    "    env = os.environ.copy()\n",
    "    commands = [\n",
    "        [\n",
    "            \"oc\",\n",
    "            \"apply\",\n",
    "            \"-f\",\n",
    "            \"https://raw.githubusercontent.com/ruivieira/lls-lmeval-reference/main/manifests/lmeval-sa.yaml\"\n",
    "        ],\n",
    "        [\n",
    "            \"oc\",\n",
    "            \"apply\",\n",
    "            \"-f\",\n",
    "            \"https://raw.githubusercontent.com/ruivieira/lls-lmeval-reference/main/manifests/lmeval-rbac.yaml\"\n",
    "        ],\n",
    "\n",
    "    ]\n",
    "    logger.info(\"Setting up roles...\")\n",
    "    for command in commands:\n",
    "        p = subprocess.Popen(args=command, env=env)\n",
    "        p.wait()\n",
    "\n",
    "setup_cluster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "configmap/trustyai-service-operator-config patched (no change)\n",
      "deployment.apps/trustyai-service-operator-controller-manager restarted\n"
     ]
    }
   ],
   "source": [
    "def enable_online_mode():\n",
    "    env = os.environ.copy()\n",
    "    commands = [\n",
    "        [\n",
    "            \"oc\",\n",
    "            \"patch\",\n",
    "            \"configmap\",\n",
    "            \"trustyai-service-operator-config\",\n",
    "            \"-n\",\n",
    "            \"redhat-ods-applications\",\n",
    "            \"--type\",\n",
    "            \"merge\",\n",
    "            \"-p\",\n",
    "            '{\"data\":{\"lmes-allow-online\":\"true\",\"lmes-allow-code-execution\":\"true\"}}'\n",
    "        ],\n",
    "        [\n",
    "           \"oc\",\n",
    "           \"rollout\",\n",
    "            \"restart\",\n",
    "            \"deployment\",\n",
    "            \"trustyai-service-operator-controller-manager\",\n",
    "            \"-n\",\n",
    "            \"redhat-ods-applications\"\n",
    "        ],\n",
    "\n",
    "    ]\n",
    "    logger.info(\"Patching the TrustyAI configmap...\")\n",
    "    for command in commands:\n",
    "        p = subprocess.Popen(args=command, env=env)\n",
    "        p.wait()\n",
    "\n",
    "enable_online_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID: lmeval-job-3\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    \"benchmark_id\": \"lmeval-1::mmlu\",\n",
    "    \"benchmark_config\": {\n",
    "        \"eval_candidate\": {\n",
    "            \"type\": \"model\",\n",
    "            \"model\": \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",\n",
    "            \"provider_id\": \"lmeval-1\",\n",
    "            \"sampling_params\": {\n",
    "                \"temperature\": 0.7,\n",
    "                \"top_p\": 0.9,\n",
    "                \"max_tokens\": 256\n",
    "            },\n",
    "        \"tokenized_\"\n",
    "        \"task_name\": \"mmlu\",\n",
    "        },\n",
    "    },\n",
    "\n",
    "}\n",
    "\n",
    "response = requests.post(f\"{url}/benchmarks/lmeval::mmlu/jobs\", json=data)\n",
    "job_id = response.json()['job_id']\n",
    "print(f\"Job ID: {job_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Get Job Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'generations': [], 'scores': {}}\n"
     ]
    }
   ],
   "source": [
    "response = requests.get(f\"{url}/benchmarks/lmeval::mmlu/jobs/lmeval-job-3/result\")\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up\n",
    "response = requests.delete(f\"{url}/benchmarks/lmeval::mmlu/jobs/{job_id}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".stack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
